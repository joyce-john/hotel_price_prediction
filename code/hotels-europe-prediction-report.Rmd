---
title: "Price Prediction for the Hotels Europe Data"
author: "John Joyce"
date: "2/14/2021"
output:
  html_document:
    theme: "paper"
    code_download: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(digits = 3)
```
# Overview
The aim of this project is to predict prices for hotels in Europe. It uses the *hotels-europe* data available [here](https://osf.io/r6uqb/). The data has features about the ratings, price, location, promotional offers, and room scarcity of the hotels. This project will focus on predicting price for a single **weekend in April 2018** in the following cities: Berlin, Munich, Vienna, Budapest, Prague, Warsaw. It will only look at hotels which cost less than 500 EUR per night. After filtering to match these criteria, the data has about 1200 observations. The mean nightly price in the sample is 138 EUR.  


# Basic Data Prep

These are the basic data preparation steps:  

1. load and join *price* and *features* tables on **hotel_id**  
2. filter the data to match the desired cities, time period, and property type (only hotels) 
3. filter the data to exclude nightly prices above 500 EUR  
4. drop NAs - there are only 54  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
################################################################################
################################################################################
###############                                                  ###############
###############                    PREPARATION                   ###############
###############                                                  ###############
################################################################################
################################################################################



##################################
###                            ###
###         BASIC SETUP        ###
###                            ###
##################################


##############################
##  loading data, libraries ##
##############################

# load  libraries
library(tidyverse)
library(skimr)
library(GGally)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(ggthemes)
library(kableExtra)


#load helper functions - used for price_diff_by_variables
source('https://raw.githubusercontent.com/joyce-john/hotel_price_prediction/main/helper_functions/da_helper_functions.R')

# load the clean tables from ym GitHub repo
price <- read_csv('https://raw.githubusercontent.com/joyce-john/hotel_price_prediction/main/data/clean/hotels-europe_price.csv')
features <- read_csv('https://raw.githubusercontent.com/joyce-john/hotel_price_prediction/main/data/clean/hotels-europe_features.csv')

# join the clean tables
data <- left_join(price, features, by = 'hotel_id')

# remove the tables after they have been joined
rm(price, features)

#####################
##  filter sample  ##
#####################

# filter cities
valid_cities <- c("Berlin", "Munich", "Vienna", "Budapest", "Prague", "Warsaw")
data <-
  data %>% 
  filter(city %in% valid_cities)

# filter data to: weekend in April 2018
data <- 
  data %>% 
  filter(year == 2018 & month == 4 & weekend == 1)

# filter data to only include hotels
data <-
  data %>% 
  filter(accommodation_type == 'Hotel')

# let's focus on non-luxury hotels and just drop everything over 500+
data <-
  data %>% 
  filter(price <= 500)

######################
##  factors/levels  ##
######################

# set character vars to factors
data <- 
  data %>% 
  mutate_if(is.character, factor)

# set levels for the discount categories
data <- 
  data %>% 
  mutate(offer_cat = factor(offer_cat, levels = c("0% no offer", "1-15% offer", "15-50% offer", "50%-75% offer", "75%+ offer")))

```
# Exploratory Data Analysis  

A quick check on the correlation among the variables show that ratings and the number of reviews are correlated with price:  

```{r, include = FALSE, warning=FALSE, message=FALSE, echo=FALSE}
##################################
###         EXPLORATORY        ###
###            DATA            ###
###          ANALYSIS          ###
##################################


# let's do some EDA + summary stats
skimr::skim(data)

# how many NAs?
sum(is.na(data))

# just 54 NAs, let's drop them
data <-
  data %>% 
  drop_na()

####################
##     price      ##
####################

# check distribution of price
data %>% 
  ggplot(aes(x = price)) + 
  geom_histogram()
# based on the distribution, log is worth considering... 
# ...but may not be necessary after dropping obs with price > 500

# choose variables for which its practical to check correlation (i.e. not factors with a bajillion levels)
check_cor <- c("price", "offer", "offer_cat", "scarce_room",              #REMOVED nnights FOR MARKDOWN
               "city", "distance", "stars", "rating", "rating_reviewcount", 
               "ratingta", "ratingta_count", "distance_alter")

# check correlations with price (and also between these variables)
plot_cor <-                                                               #ASSIGNED OBJECT FOR MARKDOWN
data %>% 
  select(all_of(check_cor)) %>% 
  ggcorr()
# stars and ratings seem to be the strongest correlated

#########################
##     ALL numerics    ##
#########################

# check distribution of all other numeric variables
data %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram()
# possible log transformations: distance, distance_alter, rating_reviewcount, ratingta_count

####################
##    distance    ##
####################

# level distance and level price
data %>% 
  ggplot(aes(x = distance, y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')

# log distance and level price
distance2 <- 
data %>% 
  ggplot(aes(x = log(distance), y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')
# more linear

# log distance and log price
data %>% 
  ggplot(aes(x = log(distance), y = log(price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')
# not much of an upgrade

##########################
##    distance_alter    ##
##########################

# level distance_alter and level price
data %>% 
  ggplot(aes(x = distance_alter, y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')

# log distance_alter and level price
data %>% 
  ggplot(aes(x = log(distance_alter), y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')
# this is the best one, despite the bump which regression won't capture

# log distance_alter and log price
data %>% 
  ggplot(aes(x = log(distance_alter), y = log(price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')
# not helpful at all

##############################
##    rating_reviewcount    ##
##############################

# level rating_reviewcount and level price
data %>% 
  ggplot(aes(x = rating_reviewcount, y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')

# log rating_reviewcount and level price
plot_log_rating_reviewcount <-                                          #ASSIGNED OBJECT FOR MARKDOWN
data %>% 
  ggplot(aes(x = log(rating_reviewcount), y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red') +
  theme_few() +
  labs(x = "ln(rating_reviewcount)", y = "Price")
# outstanding - it looks *really* linear now!

# log rating_reviewcount and log price
data %>% 
  ggplot(aes(x = log(rating_reviewcount), y = log(price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')
# also great, but doesn't suggest the log(price) is necessary

##########################
##    ratingta_count    ##
##########################

# level ratingta_count and level price
data %>% 
  ggplot(aes(x = ratingta_count, y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')

# log ratingta_count and level price
data %>% 
  ggplot(aes(x = log(ratingta_count), y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')

# log ratingta_count and log price
data %>% 
  ggplot(aes(x = log(ratingta_count), y = log(price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')

# log ratingta_count squared and log price
data %>% 
  ggplot(aes(x = log(ratingta_count)^2, y = log(price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')
# this is the most linear-looking loess for this variable

# log ratingta_count squared and level price
data %>% 
  ggplot(aes(x = log(ratingta_count)^2, y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')

# log ratingta_count cubed and level price
data %>% 
  ggplot(aes(x = log(ratingta_count)^2, y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(color = 'red')
# this is the second-most linear-looking and doesn't involve log()ing price


# well, I don't want to take log of price.
# that would be useful for linear regression, but not anything else
# and it would make model comparison slightly inconvenient

####################
##     cities     ##
####################

# check boxplots for cities
plot_city <-                                                            #ASSIGNED OBJECT FOR MARKDOWN
data %>% 
  ggplot(aes(x = city, y = price)) +
  geom_boxplot() +
  theme_few() +                                                     
  labs(x = "City", y = "Price")

#######################
##     offer_cat     ##
#######################

# check boxplots for offer category
data %>% 
  ggplot(aes(x = offer_cat, y = price)) +
  geom_boxplot()
# fascinating - the means and quantiles are quite similar!

# could cities * offer_cat be worth an interaction?
price_diff_by_variables(data, "city", "offer_cat")
# there are some differences within the cities... but I'm not convinced these are meaningful patterns
# preliminary decision: "no" to this interaction for regression models

###################
##     stars     ##
###################

# check boxplots for stars
plot_stars <-                                                           #ASSIGNED OBJECT FOR MARKDOWN
data %>% 
  ggplot(aes(x = as.factor(stars), y = price)) +
  geom_boxplot() +
  theme_few() +
  labs(x = "Stars", y = "Price")

# worth an interaction?
price_diff_by_variables(data, "city", "stars")
# no, same pattern in every city

#########################
##     city_actual     ##
#########################

# what about properties in the cities VS in nearby cities etc?
# look at the numbers
data %>% 
  mutate(is_neighbor_city = ifelse(as.character(city) != as.character(city_actual), 1, 0)) %>% 
  group_by(city, is_neighbor_city) %>% 
  summarize(mean_price = mean(price))
# generally, smaller neighbor cities are cheaper than the big city markets they belong to

# look at the boxplots
temp <-
  data %>% 
  mutate(is_neighbor_city = ifelse(as.character(city) != as.character(city_actual), 1, 0))

plot_neighbour_cities <-                                                   #ASSIGNED OBJECT FOR MARKDOWN
price_diff_by_variables(temp, "city", "is_neighbor_city")
# with the exception of Berlin, neighboring cities are usually cheaper
# this could be worth an interaction in the regression

# remove temporary dataframe
rm(temp)

```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
plot_cor
```  
  
Some of the variables have very skewed distributions, but they can be worked into a normal shape with a log transformation. One example is this **review count** variable. This can help accommodate a linear pattern between the variable and the target (price), which is helpful for linear regression.  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
plot_log_rating_reviewcount
```  

The mean prices vary from city to city, but not as much as one might expect:  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
plot_city
```  

It is apparent that the **stars** rating for a hotel is going to play an important role in predicting price:  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
plot_stars
```  

One more thing to consider is whether these hotels are actually located in the cities they are grouped with. For example, some hotels in the Berlin market are actually located in nearby Schoenefeld, not in the city of Berlin itself. With one notable exception, it seems that hotels located in neighbouring cities ("1" on this graph) are cheaper on average.  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
plot_neighbour_cities
```  

# Functional Form / Feature Engineering  

Log transformations are taken for the following variables for use in the linear regression models:  
* distance  
* distance_alter  
* ratings_reviewcount  
* ratingta_count  
  
One new feature is engineered: a binary variable which indicates whether a hotel is **actually in a neighbouring city** instead of the city given as its market. 

```{r, warning=FALSE, message=FALSE, echo=FALSE}

##################################
###                            ###
###     FEATURE ENGINEERING    ###
###                            ###
##################################


# make the variable transformations that EDA suggested would be useful for regression
data <- 
  data %>% 
  mutate(ln_distance = log(distance + 0.001),
         ln_distance_alter = log(distance_alter + 0.001),
         ln_rating_reviewcount = log(rating_reviewcount + 0.001),
         ln2_ratingta_count = log(ratingta_count + 0.001)^2)


# based on the EDA, create a new binary variable which indicates whether
# the hotel is in the city in the "city" column or whether it's in a smaller city nearby
data <-
  data %>% 
  mutate(is_neighbour_city = ifelse(as.character(city) != as.character(city_actual), 1, 0))

```  

# Prediction  

The data is split into training and test sets, with 80% of the data available for training and 20% reserved for evaluation.  

Three different model methods are used:  
* OLS linear regression  
* rpart decision tree  
* random forest  

Every model is fit on three sets of predictors, with increasing complexity:  
* **basic**: city, stars, rating, distance from the city center, review count (non-Tripadvisor)  
* **mid**: everything in basic + holidays, promotional offers, if it's a neighbouring city, and a variable interaction for OLS  
* **all**: everything in mid + any other potentially useful variable remaining (precise neighbourhood, room scarcity, another series of ratings and reviews from Tripadvisor)  

The OLS models use slightly different predictors than the tree models. OLS models use some log-transformed variables, as well as an interaction term for **city** and **is_neighbour_city** in the **mid** and **all** formulas. The tree models use untransformed variables and do not receive the interaction term, because they can uncover non-linear patterns and find interactions independently. Except for these differences, the **basic**, **mid**, and **all** formulas for OLS and tree models are the same.  

Tuning parameters for rpart and random forest are chosen via five-fold cross-validation.  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
################################################################################
################################################################################
###############                                                  ###############
###############                     PREDICTION                   ###############
###############                                                  ###############
################################################################################
################################################################################


##################################
###                            ###
###      PREDICTION SETUP      ###
###                            ###
##################################


#############################
##     train/test sets     ##
#############################

#split data into training and test sets. let's do an 80/20 split
set.seed(1413)
index <- createDataPartition(data$price, times = 1, p = 0.8, list = FALSE)

# assign training and test sets
train_set <- slice(data, index)
test_set <- slice(data, -index)

#################################
##     training parameters     ##
#################################

# set the trainControl variable for 5-fold cross validation and allow parallel processing
train_control <- trainControl(method = "cv",
                              number = 5,
                              allowParallel = TRUE)

# set the tuneGrid params for random forest
# setting mtry as the sqrt of the number of basic vars through sqrt of the number of all vars
tune_grid_rf <- expand.grid(
  .mtry = c(2, 3, 4),
  .splitrule = "variance", # for regression
  .min.node.size = c(5, 10)
)

####################################################
##     variable sets of increasing complexity     ##
####################################################

# create variable sets FOR LINEAR REGRESSION 
# includes functional form adjustments to accommodate linear patterns
# includes the is_neighbour_city*city interaction

# property stats 
linear_vars_basic <- c("city", "stars", "rating", "ln_distance", "ln_rating_reviewcount")

# property stats + circumstances (offer, holiday) + neighbor_city & interaction
linear_vars_mid <- c("offer",  "holiday", "city", "stars", "rating", "ln_distance", "ln_rating_reviewcount", "is_neighbour_city", "city*is_neighbour_city")
 
# all potential variables
linear_vars_all <- c("offer","offer_cat", "holiday",
                     "scarce_room", "city", "stars", 
                     "rating", "city_actual", "neighbourhood", 
                     "ln_distance", "ln_distance_alter", "ln_rating_reviewcount",
                     "ln2_ratingta_count", "is_neighbour_city", "city*is_neighbour_city")

# create variable sets FOR NON-LINEAR METHODS
# no functional form adjustments, because these models can find non-linear patterns
# does not includ the interaction term, because these models can find interactions automatically

# property stats
nonlinear_vars_basic <- c("city", "stars", "rating", "distance", "rating_reviewcount")

# property stats + circumstances + neighbor_city
nonlinear_vars_mid <- c("offer",  "holiday", "city", "stars", "rating", "distance", "rating_reviewcount", "is_neighbour_city")

# all potential variables
nonlinear_vars_all <- c("offer", "offer_cat", "holiday", 
                        "scarce_room", "city", "stars",
                        "rating", "city_actual", "neighbourhood",
                        "distance", "distance_alter", "rating_reviewcount",
                        "ratingta_count", "is_neighbour_city")

##################################
###                            ###
###        CREATE MODELS       ###
###                            ###
##################################

#############################
##           ols           ##
#############################

# basic
lm_1 <- train(formula(paste0("price ~", paste0(linear_vars_basic, collapse = "+"))),
              method = "lm",
              data = train_set,
              trControl = train_control)

# mid
lm_2 <- train(formula(paste0("price ~", paste0(linear_vars_mid, collapse = "+"))),
              method = "lm",
              data = train_set,
              trControl = train_control)

# all
lm_3 <- train(formula(paste0("price ~", paste0(linear_vars_all, collapse = "+"))),
              method = "lm",
              data = train_set,
              trControl = train_control)

#############################
##   rpart decision tree   ##
#############################

# basic
set.seed(1413)
tree_1 <- train(formula(paste0("price ~", paste0(nonlinear_vars_basic, collapse = "+"))),
                method = "rpart",
                data = train_set,
                trControl = train_control,
                tuneLength = 20)

# mid
set.seed(1413)
tree_2 <- train(formula(paste0("price ~", paste0(nonlinear_vars_mid, collapse = "+"))),
                method = "rpart",
                data = train_set,
                trControl = train_control,
                tuneLength = 20)

# all
set.seed(1413)
tree_3 <- train(formula(paste0("price ~", paste0(nonlinear_vars_all, collapse = "+"))),
                method = "rpart",
                data = train_set,
                trControl = train_control,
                tuneLength = 20)

#############################
##      random forest      ##
#############################

# basic
set.seed(1413)
rf_1 <- train(formula(paste0("price ~", paste0(nonlinear_vars_basic, collapse = "+"))),
                method = "ranger",
                data = train_set,
                importance = "impurity",
                trControl = train_control,
                tuneGrid = tune_grid_rf)

# mid
set.seed(1413)
rf_2 <- train(formula(paste0("price ~", paste0(nonlinear_vars_mid, collapse = "+"))),
              method = "ranger",
              data = train_set,
              importance = "impurity",
              trControl = train_control,
              tuneGrid = tune_grid_rf)

# all
set.seed(1413)
rf_3 <- train(formula(paste0("price ~", paste0(nonlinear_vars_all, collapse = "+"))),
              method = "ranger",
              data = train_set,
              importance = "impurity",
              trControl = train_control,
              tuneGrid = tune_grid_rf)
```  

# Model Evaluation

## Performance in Cross-validation  

The table below shows the mean RMSE across all five folds in cross-validation during model training. Surprisingly, the differences between the different models are fairly small. The performance of the rpart models is suspiciously homogeneous. However, manually tinkering with the tuning parameters only increased the variation among these models by making some of them worse.  
  
The OLS models benefited from increasing complexity, but the most complex random forest suffered from the worst RMSE out of all nine models. One possible explanation: including review and rating information from multiple sources (only available in the **all** model) may have been a mistake: these features are highly correlated with one another, and this may have led to excessively correlated trees in the random forest.  

**The selected model is random forest model 2**, because it has the lowest RMSE in cross-validation.  

```{r, warning=FALSE, message=FALSE, echo=FALSE}

##################################
###                            ###
###      EVALUATE MODELS       ###
###                            ###
##################################

########################################
##      cross-validation results      ##
########################################

# vector of model names
models <- c('OLS 1', 'OLS 2', 'OLS 3', 'Rpart 1', 'Rpart 2', 'Rpart 3', 'Random forest 1', 'Random forest 2', ' Random forest 3')

# vector of variable descriptors, manually ordered to match
variable_detail <- c('basic', 'mid', 'all','basic', 'mid', 'all','basic', 'mid', 'all')

# dataframe of RMSE / minimum mean cross-validated RMSE for optimal tuning values for all the models
cv_results <- data.frame("Model" = models, "Variables" = variable_detail, "Mean_RMSE" = c(lm_1$results$RMSE, lm_2$results$RMSE, lm_3$results$RMSE,
                                                                                          min(tree_1$results$RMSE), min(tree_2$results$RMSE), min(tree_3$results$RMSE),
                                                                                          min(rf_1$results$RMSE), min(rf_2$results$RMSE), min(rf_3$results$RMSE)))

# rf_2 has the lowest RMSE in cross-validation, therefore I select it as my model

cv_results %>% kable() %>% kable_styling()

```  

## Performance on the Test Set  

The best model performs even better on the test set. The **RMSE is 48.1** (vs 51.2 in cross-validation) and the **mean absolute error** is 32.6.  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
########################################
##          test-set results          ##
########################################

#use rf_2 model to create a vector of predictions on test set obs
rf_2_predictions <- predict(rf_2, test_set)

# calculate RMSE for predictions on test set
test_set_rmse <- RMSE(rf_2_predictions, test_set$price) # 48.08499
test_set_mae <- caret::MAE(rf_2_predictions, test_set$price) # 32.63675
```  

## Residuals and Diagnostics

The model has some weaknesses. It does not perform equally well in all of the cities in the sample. In fact, it performs particularly poorly in Budapest.  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
########################################
##         model diagnostics          ##
########################################

# add prediction and RMSE column to test set data so we can analyze errors
test_set <- 
  test_set %>% 
  mutate(prediction = rf_2_predictions)

# do errors differ by city? look at the numbers                               ### NOT RUN FOR MARKDOWN
# test_set %>% 
#   group_by(city) %>% 
#   summarize(rmse = RMSE(price, prediction))

# do errors differ by city? look at the graph
test_set %>% 
  group_by(city) %>% 
  summarize(rmse = RMSE(price, prediction)) %>% 
  ggplot(aes(x = reorder(city, rmse), y = rmse)) +
  geom_bar(stat = 'identity') +
  theme_few() +
  labs(x = 'City', y = "RMSE", title = "RMSE on the Test Set") +
  theme(plot.title = element_text(hjust = 0.5))
```  
  
Below are the top ten *negative* prediction errors, where the model predicted a price which is too low. There is no general pattern visible here, except that the prices are all significantly above the mean of 138 EUR. The top two errors are in Budapest, contributing to the poor RMSE for that group.   
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# top 10 negative prediction errors as a table
test_set %>% 
  mutate(error = prediction - price) %>% 
  arrange(error) %>% 
  select(hotel_id, city, distance, stars, rating, rating_reviewcount,price, prediction, error) %>% 
  slice_head(n = 10) %>% 
  kable() %>% 
  kable_styling()
# no real pattern here, but the two biggest errors are in Budapest, which has the highest RMSE in general
```  
  
Below are the top ten *positive* prediction errors, where the model predicted a price which is too high. The pattern here is perfectly clear: the model is struggling with hotels in Prague.  

```{r, warning=FALSE, message=FALSE, echo=FALSE}
# top ten positive prediction errors as a table
test_set %>% 
  mutate(error = prediction - price) %>% 
  arrange(desc(error)) %>% 
  select(hotel_id, city, distance, stars, rating, rating_reviewcount,price, prediction, error) %>% 
  slice_head(n = 10) %>% 
  kable() %>% 
  kable_styling()
# 8/10 are in Prague!!
```  
  
The variable importance plot shows that **stars** is the most important variable by a considerable margin.  
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# look at the most important variables (varImp plot)
plot(varImp(rf_2))
```  
  
The partial dependence plot for the **stars** variable in the model shows that the expected value for price is quite higher when the number of stars is high.  
```{r, warning=FALSE, message=FALSE, echo=FALSE}

# partial dependence plot for stars on price
# calculate partial dependence
pdp_stars <- pdp::partial(rf_2, pred.var = "stars", pred.grid = distinct_(test_set, "stars"), train = train_set)

# plot partial dependence and save to an object
pdp_stars_plot <- pdp_stars %>%
  autoplot( ) +
  geom_point(size=3) +
  geom_line(size=1) +
  ylab("Predicted Price") +
  xlab("Stars") +
  labs(title = "Partial Dependence Plot: Stars and Price") +
  scale_x_continuous(limit=c(1.5,5), breaks=seq(1.5,5,0.5)) +
  theme_few() +
  theme(plot.title = element_text(hjust = 0.5))

# show partial dependence plot
pdp_stars_plot

```  
  
# Conclusion

The best model achieves an **RMSE of 51.2 in cross-validation** and **48.1 on the test set**. This is a stable and decent performance. With an **MAE of 32.6 on the test set**, one can expect to predict hotel prices on this population with an average error of 32.6 EUR, using only basic and public information. The biggest weakness of this model is its poor performance in Budapest and Prague. If predictions in these two cities could be improved, the model would have considerably better performance metrics overall.  
  
Thinking external validity: this particular iteration of the model would likely not be useful today due to the different circumstances in hotel pricing due to COVID. However, it might be worth re-fitting with the same formula in a post-pandemic world.